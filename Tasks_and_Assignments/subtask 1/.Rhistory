# fit
model = lm(yr~log_data, data = df )
print(paste("model summary:\n", summary(model)))
# intercepts
alpha = exp(coef(model)[1])
beta = coef(model)[2]
cat("The alpha value is and the beta value is:\n\t", alpha, "\t", beta,"\n")
val = exp(log_data)
predicted = alpha * exp(beta * val)
return(predicted)
}
exp_data$exp_trend = exp_Data(exp_data, "year", "subscribers")
exp_data
exp_Data = function(df,x, y){
# transform
log_data = log(df[[y]])
yr = df[[x]]
# fit
model = lm(yr~log_data, data = df )
print(paste("model summary:\n", summary(model)))
# intercepts
alpha = exp(coef(model)[1])
beta = coef(model)[2]
cat("The alpha value is and the beta value is:\n\t", alpha, "\t", beta,"\n")
val = exp(log_data)
predicted = alpha * exp(beta * val)
return(predicted)
}
exp_data$exp_trend = exp_Data(exp_data, "year", "subscribers")
exp_data
exp_Data = function(df,x, y){
# transform
log_data = log(df[[y]])
yr = df[[x]]
# fit
model = lm(log_data~yr, data = df )
print(paste("model summary:\n", summary(model)))
# intercepts
alpha = exp(coef(model)[1])
beta = coef(model)[2]
cat("The alpha value is and the beta value is:\n\t", alpha, "\t", beta,"\n")
val = exp(log_data)
predicted = alpha * exp(beta * val)
return(predicted)
}
exp_data$exp_trend = exp_Data(exp_data, "year", "subscribers")
exp_data
exp_Data = function(df,x, y){
# transform
log_data = log(df[[y]])
yr = df[[x]]
# fit
model = lm(log_data~yr, data = df )
print(paste("model summary:\n", summary(model)))
# intercepts
alpha = exp(coef(model)[1])
beta = coef(model)[2]
cat("The alpha value is and the beta value is:\n\t", alpha, "\t", beta,"\n")
predicted = alpha * exp(beta * yr)
return(predicted)
}
exp_data$exp_trend = exp_Data(exp_data, "year", "subscribers")
exp_data
exp_Data = function(df,x, y){
# transform
log_data = log(df[[y]])
yr = df[[x]]
# fit
model = lm(log_data~yr, data = df )
print(paste("model summary:\n", summary(model)))
# intercepts
alpha = exp(coef(model)[1])
beta = coef(model)[2]
cat("The alpha value is and the beta value is:\n\t", alpha, "\t", beta,"\n")
val = data[[x]]
predicted = alpha * exp(beta * val)
return(predicted)
}
exp_data$exp_trend = exp_Data(exp_data, "year", "subscribers")
exp_Data = function(df,x, y){
# transform
log_data = log(df[[y]])
yr = df[[x]]
# fit
model = lm(log_data~yr, data = df )
print(paste("model summary:\n", summary(model)))
# intercepts
alpha = exp(coef(model)[1])
beta = coef(model)[2]
cat("The alpha value is and the beta value is:\n\t", alpha, "\t", beta,"\n")
val = df[[x]]
predicted = alpha * exp(beta * val)
return(predicted)
}
exp_data$exp_trend = exp_Data(exp_data, "year", "subscribers")
exp_data
0 * exp( 0.5395523 * exp_data[["year"]])
0 * exp( 0.5395523 * exp_data[,"year"])
exp( 0.5395523 * exp_data[,"year"])
Inf * 0
exp_Data = function(df,x, y){
# transform
log_data = log(df[[y]])
yr = df[[x]]
# fit
model = lm(log_data~yr, data = df )
print(paste("model summary:\n", summary(model)))
# intercepts
alpha = exp(coef(model)[1])
beta = coef(model)[2]
cat("The alpha value is and the beta value is:\n\t", alpha, "\t", beta,"\n")
val = df[[x]]
predicted = alpha * exp(beta * val)
return(predicted)
}
season = rep(c("summer", "monsoon", "winter", "spring"), 3)
data = data.frame(season = season,
year = c(rep(2020, 4),
rep(2021, 4),
rep(2022, 4)),
levels = c(70, 52, 22, 31, 101, 64, 24, 45, 146, 92, 38, 49))
data
library(zoo)
data$moving_avg =  rollapply(data$levels, width = 4, FUN = mean, align = 'right', fill = NA)
data
wgt = c(1, 2, 3, 4)
weighted_avg = function(x){
sum(x * wgt)/ sum(wgt)
}
data$wgt_avg = rollapply(data$levels, width = 4, FUN = weighted_avg, align = 'right', fill = NA)
data
x = seq(1, 9)
plot_data = data.frame(x,
moving_avg = na.omit(data$moving_avg),
wgt_mvn_avg = na.omit(data$wgt_avg))
plot_data
library(ggplot2)
ggplot(plot_data, aes(x=x))+
geom_line(aes(y = moving_avg), color = "blue")+
geom_line(aes(y = wgt_mvn_avg), color = "red")
labs(title = "Line Graphs of Moving Averages",
x = "X",
y = "Values") +
scale_color_manual(name = "Legend", values = c("moving_avg" = "blue", "wgt_mvn_avg" = "red")) +
theme_minimal()
ggplot(data, aes(x = seq(1,12)))+
geom_line(aes(y = moving_avg), color = "blue")+
geom_line(aes(y = wgt_avg), color = "red")+
geom_line(aes(y = levels), color = "green")+
labs(title = "Line Graphs of Moving Averages",
x = "X",
y = "Values") +
scale_color_manual(name = "Legend", values = c("moving_avg" = "blue", "wgt_mvn_avg" = "red","original data" = "green")) +
theme_minimal()
exp_data = data.frame(year = c(rep(2018, 3),
rep(2019, 3),
rep(2020, 3),
rep(2021, 3)),
period = rep(c("I", "II", "III"), 4),
no_claims = c(17, 13, 15, 19, 17, 19, 22, 14, 20, 23, 19, 20))
exp_data
exp_smooth = function(alpha, x){
a = c(x[1])
b = length(a)
for(i in c(2:length(x))){
val = (alpha * x[i]) + (1- alpha) * a[i -1]
a = c(a,val)
}
return(a)
}
x_exp = exp_data$no_claims
exp_data$alpha_0.2 = exp_smooth(0.2, x_exp)
exp_data$alpha_0.4 = exp_smooth(0.4, x_exp)
exp_data$alpha_0.6 = exp_smooth(0.6, x_exp)
exp_data$alpha_0.8 = exp_smooth(0.8, x_exp)
exp_data
ggplot(exp_data, aes(x = seq(1, 12)))+
geom_line(aes(y = no_claims), color = "blue")+
geom_line(aes(y = alpha_0.2), color = "red")+
geom_line(aes(y = alpha_0.4), color = "green")+
geom_line(aes(y = alpha_0.6), color = "purple")+
geom_line(aes(y = alpha_0.8), color = "orange")+
labs(title = "Line Graphs of Moving Averages",
x = "X",
y = "Values") +
scale_color_manual(name = "Legend", values = c("original" = "blue", "alpha 0.2" = "red","alpha 0.4" = "green", "alpha 0.6" = "purple", "alpha 0.8" = "orange")) +
theme_minimal()
reg_data = data.frame(year = seq(2010, 2018),
sales = c(52, 54, 48, 60, 61, 66, 70, 80, 92))
med_yr = median(reg_data$year)
reg_data$x_t = reg_data$year - med_yr
reg_data
reg_data$x_y = reg_data$x_t * reg_data$x_t
reg_data$x_t_sqrd = reg_data$x_t ^ 2
reg_data
summary(lm(sales~x_t, data = reg_data))
lm(sales~x_t, data = reg_data)$coefficients
reg_data$smooth = 4.80000 * reg_data$x_t + 64.77778
reg_data
library(ggplot2)
ggplot(aes(x = year), data = reg_data)+
geom_line(aes(y = sales, color = "original"))+
geom_line(aes(y = smooth, color = "smoothed"))+
labs(
title = "regressive smoothing of sales for each year",
x = "year",
y = "sales"
)+
scale_color_manual(name = "Legend", values = c("original" = "blue", "smoothed" = "red"))+
theme_minimal()
reg_data$quad_smooth = predict(loess(sales~x_t, reg_data), reg_data)
reg_data
ggplot(aes(x = year), data = reg_data)+
geom_line(aes(y = sales, color = "original"))+
geom_line(aes(y = smooth, color = "smoothed"))+
geom_line(aes(y = quad_smooth, color = "qsmoothed"))+
labs(
title = "regressive smoothing of sales for each year",
x = "year",
y = "sales"
)+
scale_color_manual(name = "Legend", values = c("original" = "blue", "smoothed" = "red", "qsmoothed" = "green"))+
theme_minimal()
exp_data = data.frame(year = seq(2015, 2022),
revenue = c(15, 45, 52, 75, 106, 158, 241, 314))
exp_data
exp_data$t = exp_data$year - median(exp_data$year)
exp_data$t_sqrd = exp_data$t^2
exp_data$zt = log(exp_data$revenue)
exp_data
exp_n = nrow(exp_data)
cat("Beta_0 of the data is: ",exp(sum(exp_data$zt)/ exp_n), "\n")
exp_data$tzt = exp_data$t * exp_data$zt
exp_data
cat("Beta_1 is given as: ", sum(exp_data$tzt)/ sum(exp_data$t_sqrd), "\n")
beta_1 = 0.3971438
beta_0 = 87.17857
exp_data$smoothed = beta_0  * exp(beta_1 * exp_data$t)
exp_data
library(ggplot2)
ggplot(aes(x = year), data = exp_data)+
geom_point(aes(y = revenue, color = "original"))+
geom_line(aes(y = smoothed, color = "smoothed"))+
labs(
title = "exponential smoothing",
x = "year",
y = "trend"
)+
scale_color_manual(name = "Legend", values = c("original" = "red", "smoothed" = "blue"))+
theme_minimal()
exp_Data = function(df,x, y){
# transform
log_data = log(df[[y]])
yr = df[[x]]
# fit
model = lm(log_data~yr, data = df )
print(paste("model summary:\n", summary(model)))
# intercepts
alpha = exp(coef(model)[1])
beta = coef(model)[2]
cat("The alpha value is and the beta value is:\n\t", alpha, "\t", beta,"\n")
val = df[[x]]
predicted = alpha * exp(beta * val)
return(predicted)
}
exp_data$func_smth = exp_Data(exp_data, "t", "revenue")
View(exp_data)
exp_data$t = exp_data$year - median(exp_data$year)
knitr::opts_chunk$set(echo = TRUE)
task_data = data.frame(year = seq(2011, 2020),
GDP = c(35, 37, 51, 54, 62, 64, 74, 71, 83, 80))
task_data
med_yr = median(task_data$year)
task_data$zero_yr = task_data$year - med_yr
task_data
trend = lm(GDP~zero_yr, data = task_data)
trend$coefficients
# create the reg_smooth data
Beta_0 = trend$coefficients[1]
Beta_1 = trend$coefficients[2]
task_data$reg_smooth = Beta_1 * task_data$zero_yr + Beta_0
task_data
quad_smth = loess(GDP~zero_yr, task_data)
task_data$quad_smth = predict(quad_smth, task_data)
task_data
# regressive smoothing
summary(trend)$r.squared
# quadratic smoothing
mean_GDP = mean(task_data$GDP)
SST = sum((task_data$GDP - mean_GDP)^2)
residuals = residuals(quad_smth)
SSE = sum(residuals^2)
R_squared = 1 - (SSE / SST)
R_squared
library(ggplot2)
ggplot(aes(x = year), data = task_data)+
geom_line(aes(y = GDP, color = "original"))+
geom_line(aes(y = reg_smooth, color = "reg_smooth"))+
geom_line(aes(y = quad_smth, color = "quad_smth"))+
labs(
title = "GDP to Year Data",
x = "year",
y = "GDP"
)+
scale_color_manual(name = "Legend", values = c("original" = "black", "reg_smooth"= "red", "quad_smth"= "blue"))+
theme_minimal()
task_data$forecst_err_linear = task_data$GDP - task_data$reg_smooth
task_data$forecst_err_quad = task_data$GDP - task_data$quad_smth
task_data
cat("The forecast errors are:\n\nYear:", seq(2011, 2019),"\n\nLinear smoothing Err :", task_data$forecst_err_linear, "\n\nQuadratic smoothing Err :", task_data$forecst_err_quad)
new_data = data.frame(zero_yr = 2022 - med_yr)
predicted_gdp = predict(trend, newdata = new_data)
cat("The GDP for 2022 is predicted to be: ", predicted_gdp, "\n")
loes_val = data.frame(year = seq(2011, 2022),
GDP =predict(quad_smth, newdata = data.frame(zero_yr = seq(2011, 2022) - median(seq(2011, 2022)))))
loes_val
zero_yr_range  =  seq(min(task_data$zero_yr), max(task_data$zero_yr), length.out = 100)
predicted_values  =  predict(quad_smth, newdata = data.frame(zero_yr = zero_yr_range))
loes_df = data.frame(zero_yr = zero_yr_range, pred = predicted_values)
poly_fit  =  lm(predicted_values ~ zero_yr_range)
coefficients(poly_fit)
Coeffs = coefficients(poly_fit)
loes_n = nrow(task_data)
loes_yt = sum(task_data$GDP)
loes_xt = sum(task_data$zero_yr)
loes_xt_2 = sum(task_data$zero_yr ^ 2)
loes_beta_2 = (loes_yt - (loes_n * Coeffs[1]) - (Coeffs[2] * loes_xt))/ loes_xt_2
cat("The GDP for 2022 is predicted to be: ", Coeffs[1] + (2022 - med_yr) * Coeffs[2] + (2022 - med_yr)^2 * loes_beta_2, "\n")
new_data = data.frame(x = task_data$zero_yr,
y = task_data$GDP)
new_data$x_sqrd = new_data$x^2
new_data$x_y = new_data$x * new_data$y
new_data$x_cubed = new_data$x^3
new_data$x_quad = new_data$x^4
new_data$x_2_y = new_data$x_sqrd * new_data$y
new_data
b = c(sum(new_data$y), sum(new_data$x_y), sum(new_data$x_2_y))
val_1 = sum(new_data$x)
val_2 = sum(new_data$x_sqrd)
val_3 = sum(new_data$x_cubed)
val_4 =  sum(new_data$x_quad)
a = matrix(c(10, val_1, val_2,
val_1, val_2, val_3,
val_2, val_3, val_4), byrow = TRUE, nrow = 3)
a
coef_x = solve(a, b)
coef_x
cat("The corrected GDP using math formula is:\n\t ", coef_x[1] + (2022 - med_yr) * coef_x[2] + (2022 - med_yr)^2 * coef_x[3])
task_data$math_quad = coef_x[1] + task_data$zero_yr * coef_x[2] + task_data$zero_yr^2 * coef_x[3]
task_data
library(ggplot2)
ggplot(aes(x = year), data = task_data)+
geom_line(aes(y = GDP, color = "original"))+
geom_line(aes(y = reg_smooth, color = "reg_smooth"))+
geom_line(aes(y = quad_smth, color = "quad_smth"))+
labs(
title = "GDP to Year Data",
x = "year",
y = "GDP"
)+
scale_color_manual(name = "Legend", values = c("original" = "black", "reg_smooth"= "red", "quad_smth"= "blue"))+
theme_minimal()
exp_data = data.frame(year= seq(2014, 2021),
subscribers = c(2, 5, 11, 20, 35, 50, 70, 95))
exp_data
exp_Data = function(df,x, y){
# transform
log_data = log(df[[y]])
yr = df[[x]]
# fit
model = lm(log_data~yr, data = df )
print(paste("model summary:\n", summary(model)))
# intercepts
alpha = exp(coef(model)[1])
beta = coef(model)[2]
cat("The alpha value is and the beta value is:\n\t", alpha, "\t", beta,"\n")
val = df[[x]]
predicted = alpha * exp(beta * val)
return(predicted)
}
exp_data$t = exp_data$year - median(exp_data$year)
exp_data$exp_trend = exp_Data(exp_data, "t", "subscribers")
exp_data
exp_data$forecst_err = exp_data$subscribers - exp_data$exp_trend
exp_data
predict = function(alpha, beta, target){
return(alpha * exp(beta * target))
}
pred_subs = function(alpha, beta, target){
return(alpha * exp(beta * target))
}
med = median(exp_data$year)
target = 2024 - med
cat("The predicted subsribers are:\n\t",pred_subs(20.00024, 0.5395523, target), "\n")
med = median(exp_data$year)
target = 2024 - med
cat("The predicted subsribers are:\n\t",round(pred_subs(20.00024, 0.5395523, target)), "\n")
install.packages("writexlsx")
install.packages("writexl")
knitr::opts_chunk$set(echo = TRUE)
options(scipen = 999)
library(readr)
data_1 = read_csv("Iran Twitter NodeXL SNA UTC 1.csv")
head(data_1)
problems(data_1)
spec(data_1)
na_counts = colSums(is.na(data_1))
rem_cols = which(na_counts < nrow(data_1))
data_1 = data_1[, rem_cols]
head(data_1)
data_2 = read_csv("Iran Twitter NodeXL SNA UTC 2.csv")
na_counts_2 = colSums(is.na(data_2))
rem_cols_2 = which(na_counts_2 < nrow(data_2))
data_2 = data_2[, rem_cols_2]
head(data_1)
colnames(data_2)
str(data_1)
feature_data_1 = c('Tweet', 'Retweet Count', 'Favorite Count', 'Reply Count','Quote Count', 'Impression Count', 'Hashtags in Tweet', 'URLs in Tweet','Domains in Tweet', 'Mentions in Tweet', 'Media in Tweet', 'Language','Possibly Sensitive', 'Author ID')
key_data_1 = data_1[, feature_data_1]
head(key_data_1)
important_attributes_2 = c('Tooltip', 'Tweets', 'User ID', 'Verified', 'Followers', 'Followed', 'Description', 'Location','Favourites Count', 'Possibly Sensitive', 'Is Blue Verified', 'Can DM', "Tweeted Search Term?"
)
key_data_2 = data_2[,important_attributes_2]
head(key_data_2)
library(randomForest)
library(caret)
set.seed(124)
key_data_2$Verified = as.factor(key_data_2$Verified)
key_data_2$`Is Blue Verified` = as.factor(key_data_2$`Is Blue Verified`)
key_data_2$`Possibly Sensitive` = as.factor(key_data_2$`Is Blue Verified`)
key_data_2$`Can DM` = as.factor(key_data_2$`Can DM`)
key_data_2$`Tweeted Search Term?` = as.factor(key_data_2$`Tweeted Search Term?`)
key_data_2$`Favourites Count` = as.numeric(key_data_2$`Favourites Count`)
indexes = sample(nrow(key_data_2), floor(0.7 * nrow(key_data_2)))
train_data = key_data_2[indexes, ]
test_data = key_data_2[-indexes, ]
nrow(test_data)
nrow(train_data)
# dropping na values in train data
train_data_2 = na.omit(train_data)
train_data_2 = train_data_2[, !(names(train_data_2) %in% c("Tooltip", "Tweets", "User ID", "Description", "Location"))]
snake_case = function(x){
output = gsub(" ", "_", x )
return(output)
}
names(train_data_2)[names(train_data_2) == "Favourites Count"] = snake_case("Favourites Count")
names(train_data_2)[names(train_data_2) == "Possibly Sensitive"] = snake_case("Possibly Sensitive")
names(train_data_2)[names(train_data_2) == "Is Blue Verified"] = snake_case("Is Blue Verified")
names(train_data_2)[names(train_data_2) == "Can DM"] = snake_case("Can DM")
names(train_data_2)[names(train_data_2) == "Tweeted Search Term?"] = snake_case("Tweeted Search Term?")
library(writexl)
write_xlsx("train_data.csv", train_data_2)
?write_xlsx
library(writexl)
write_xlsx(train_data_2, "train_data.csv")
write_xlsx(test_data, "test_data.csv")
knitr::opts_chunk$set(echo = TRUE)
options(scipen = 999)
library(writexl)
write_xlsx(train_data_2, "train_data.xlsx")
write_xlsx(test_data, "test_data.xlsx")
library(writexl)
write_csv(train_data_2, "train_data.csv")
library(openxlsx)
write_csv(train_data_2, "train_data.csv")
library(openxlsx)
write.csv(train_data_2, "train_data.csv")
write.csv(test_data, "test_data.csv")
setwd("C:/Users/ADMIN/Documents/SEM 2 2024/STA3050 time series/Tasks_and_Assignments/subtask 1")
knitr::opts_chunk$set(echo = TRUE)
sales_data = data.frame(
Year = c(2018, 2019, 2020),
Q1 = c(48, 58, 60),
Q2 = c(41, 52, 58),
Q3 = c(60, 68, 75),
Q4 = c(65, 74, 78)
)
sales_data
sales_long = pivot_longer(sales_data, cols = starts_with("Q"), names_to = "Quarter", values_to = "Sales")
library(tidyr)
sales_long = pivot_longer(sales_data, cols = starts_with("Q"), names_to = "Quarter", values_to = "Sales")
sales_long
na * 3
NA * 3
rep(NA, 3)
c(NA, NA, mean(sales_data$Q1), mean(sales_data$Q1))
sales_data$mean_Q1 = c(NA, NA, mean(sales_data$Q1), mean(sales_data$Q1))
sales_data$annual_means = colMeans(sales_data[2:ncol(sales_data)])
sales_data$annual_means = rowMeans(sales_data[,2:ncol(sales_data)])
sales_data
sales_data$monthly_avg = sales_data$annual_means/mean(sales_data$annual_means) * 100
sales_data
predictors = lm(year~annual_mean, data = sales_data)$coeff
predictors = lm(Year~annual_mean, data = sales_data)$coeff
predictors = lm(Year~annual_mean, data = sales_data)$Coefficients
predictors = summary(lm(Year~annual_mean, data = sales_data))$coefficients
predictors = summary(lm(Year~annual_mean, data = sales_data))$coeff
predictors = summary(lm(Year~annual_means, data = sales_data))$coeff
predictors
predictors = summary(lm(Year~annual_means, data = sales_data))
predictors
predictors = summary(lm(Year~annual_means, data = sales_data))$Estimate
predictors
predictors = summary(lm(Year~annual_means, data = sales_data))$Coefficients$Estimate
predictors
predictors = summary(lm(Year~annual_means, data = sales_data))$Coefficients
predictors
predictors = summary(lm(Year~annual_means, data = sales_data))$Estimate
predictors
predictors = coeff(lm(Year~annual_means, data = sales_data))
predictors = coef(lm(Year~annual_means, data = sales_data))
predictors
