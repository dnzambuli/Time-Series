conf.int = TRUE,
pval = TRUE,
risk.table = TRUE,
linetype = "strata",
surv.median.line = "hv",
ggtheme = theme_minimal(),
title = paste("Survival Curve for", column))
interest_disease$Mental_Detected = as.factor(interest_disease$Mental_Detected)
fit = surv_fit(surv_dses~Mental_Detected, data = interest_disease)
ggsurvplot(fit,
data = interest_disease,
conf.int = TRUE,
pval = TRUE,
risk.table = TRUE,
linetype = "strata",
surv.median.line = "hv",
ggtheme = theme_minimal(),
title = paste("Survival Curve for", Mental_Detected))
colnames(interest_disease)
interest_disease$Mental_Detected = as.factor(interest_disease$Mental_Detected)
fit = surv_fit(surv_dses~Mental_Detected, data = interest_disease)
ggsurvplot(fit,
data = interest_disease,
conf.int = TRUE,
pval = TRUE,
risk.table = TRUE,
linetype = "strata",
surv.median.line = "hv",
ggtheme = theme_minimal(),
title = paste("Survival Curve for", Mental_Detected))
interest_disease$Mental_Detected
fit
interest_disease$Mental_Detected = as.factor(interest_disease$Mental_Detected)
fit = surv_fit(surv_dses~Mental_Detected, data = interest_disease)
ggsurvplot(fit,
data = interest_disease,
conf.int = TRUE,
pval = TRUE,
risk.table = TRUE,
linetype = "strata",
surv.median.line = "hv",
ggtheme = theme_minimal(),
title = paste("Survival Curve for", as.character(Mental_Detected)))
interest_disease$Mental_Detected = as.factor(interest_disease$Mental_Detected)
fit = surv_fit(surv_dses~Mental_Detected, data = interest_disease)
ggsurvplot(fit,
data = interest_disease,
conf.int = TRUE,
pval = TRUE,
risk.table = TRUE,
linetype = "strata",
surv.median.line = "hv",
ggtheme = theme_minimal(),
title = "Survival Curve for (Mental Illness Detected)")
ggplot(base_haz, aes(x = time, y = hazard))+
geom_line()+
labs(x = "Days",
y = "Hazard",
title = "Baseline Hazard Function")+
scale_x_continuous(breaks = breaks, limits = c(0, 900))
haz_fit_resident = coxph(Surv(time = duration, event = event_observed)~1, data = clean_resident)
base_haz_resident = basehaz(haz_fit_resident, centered = F)
summary(haz_fit_resident)
ggplot(base_haz_resident, aes(x = time, y = hazard))+
geom_line()+
labs(x = "Days",
y = "Hazard",
title = "Baseline Hazard Function for In-Patient")+
scale_x_continuous(breaks = breaks, limits = c(0, 900))
haz_fit_non_resident = coxph(Surv(time = duration, event = event_observed)~1, data = clean_non_resident)
base_haz_non_resident = basehaz(haz_fit_non_resident, centered = F)
summary(haz_fit_non_resident)
ggplot(base_haz_non_resident, aes(x = time, y = hazard))+
geom_line()+
labs(x = "Days",
y = "Hazard",
title = "Baseline Hazard Function for Out-Patient")+
scale_x_continuous(breaks = breaks, limits = c(0, 900))
library(survival)
p = ggsurvplot(km_fit, fun = "cumhaz",
xlab = "Days",
ylab = "Cumulative Hazard",
title = "Nelson-Aalen Cumulative Hazard Curve")
p$plot = p$plot + scale_x_continuous(breaks = breaks, limits = c(0, 900))
p
library(survival)
c = ggsurvplot(km_fit, fun = "cumhaz",
xlab = "Days",
ylab = "Cumulative Hazard",
title = "Nelson-Aalen Cumulative Hazard Curve")
c$plot = c$plot + scale_x_continuous(breaks = breaks, limits = c(0, 900))
c
breaks <- c(6, 18, 36, 54, seq(100, 820, by = 100))
library(survival)
c = ggsurvplot(km_fit, fun = "cumhaz",
xlab = "Days",
ylab = "Cumulative Hazard",
title = "Nelson-Aalen Cumulative Hazard Curve")
c$plot = c$plot + scale_x_continuous(breaks = breaks, limits = c(0, 900))
c
km_fit_resident = survfit(Surv(time = duration, event = event_observed)~1, data = clean_resident)
summary(km_fit_resident)
ggsurvplot(km_fit_resident, data = clean_resident,
pval = TRUE, conf.int = TRUE,
risk.table = TRUE,
risk.table.col = "strata",
ggtheme = theme_bw(),
palette = c("#E7B800", "#2E9FDF"),
xlab = "Days",
ylab = "Survival Probability",
title = "Kaplan-Meier Survival Curve")
ggsurvplot(km_fit_resident, data = clean_resident,
pval = TRUE, conf.int = TRUE,
risk.table = TRUE,
risk.table.col = "strata",
ggtheme = theme_bw(),
palette = c("#E7B800", "#2E9FDF"),
xlab = "Days",
ylab = "Survival Probability",
title = "Kaplan-Meier Survival Curve")+
scale_x_continuous(breaks = breaks, limits = c(0, 900))
ggsurvplot(km_fit_resident, data = clean_resident,
pval = TRUE, conf.int = TRUE,
risk.table = TRUE,
risk.table.col = "strata",
ggtheme = theme_bw(),
palette = c("#E7B800", "#2E9FDF"),
xlab = "Days",
ylab = "Survival Probability",
title = "Kaplan-Meier Survival Curve")$plot +
scale_x_continuous(breaks = breaks, limits = c(0, 900))
breaks <- c(6, 18, 36, 54, seq(100, 820, by = 100))
library(survival)
c = ggsurvplot(km_fit, fun = "cumhaz",
xlab = "Days",
ylab = "Cumulative Hazard",
title = "Nelson-Aalen Cumulative Hazard Curve")$plot +
scale_x_continuous(breaks = breaks, limits = c(0, 900))
c
breaks <- c(6, 18, 36, 54, seq(100, 820, by = 100))
library(survival)
ggsurvplot(km_fit, fun = "cumhaz",
xlab = "Days",
ylab = "Cumulative Hazard",
title = "Nelson-Aalen Cumulative Hazard Curve")$plot +
scale_x_continuous(breaks = breaks, limits = c(0, 900))
breaks <- c(6, 18, 36, 54, seq(100, 820, by = 100))
library(survival)
ggsurvplot(km_fit, fun = "cumhaz",
xlab = "Days",
ylab = "Cumulative Hazard",
title = "Nelson-Aalen Cumulative Hazard Curve") +
scale_x_continuous(breaks = breaks, limits = c(0, 900))
breaks <- c(6, 18, 36, 54, seq(100, 820, by = 100))
library(survival)
ggsurvplot(km_fit, fun = "cumhaz",
xlab = "Days",
ylab = "Cumulative Hazard",
title = "Nelson-Aalen Cumulative Hazard Curve")$plot +
scale_x_continuous(breaks = breaks, limits = c(0, 900))
breaks <- c(6, 18, 36, 54, seq(100, 820, by = 100))
library(survival)
a = ggsurvplot(km_fit, fun = "cumhaz",
xlab = "Days",
ylab = "Cumulative Hazard",
title = "Nelson-Aalen Cumulative Hazard Curve")
a$plot = $plot +
breaks <- c(6, 18, 36, 54, seq(100, 820, by = 100))
library(survival)
a = ggsurvplot(km_fit, fun = "cumhaz",
xlab = "Days",
ylab = "Cumulative Hazard",
title = "Nelson-Aalen Cumulative Hazard Curve")
a$plot = a$plot + scale_x_continuous(breaks = breaks, limits = c(0, 900))
print(a)
breaks <- c(6, 18, 36, 54, seq(100, 820, by = 100))
library(survival)
a = ggsurvplot(km_fit, fun = "cumhaz",
xlab = "Days",
ylab = "Cumulative Hazard",
title = "Nelson-Aalen Cumulative Hazard Curve")
a$plot = a$plot + scale_x_continuous(breaks = breaks, limits = c(0, 900))
print(a$plot)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(agricolae)
q1_data = data.frame(Fields = rep(1:5, each = 5),
Acre = rep(1:5, times = 5),
Treatment = c('B', 'D', 'E', 'A', 'C',
'C', 'A', 'B', 'E', 'D',
'D', 'C', 'A', 'B', 'E',
'E', 'B', 'C', 'D', 'A',
'A', 'E', 'D', 'C', 'B'),
Yield = c(4.9, 6.4, 3.3, 9.5, 11.8,
9.3, 4.0, 6.2, 5.1, 5.4,
7.6, 15.4, 6.5, 6.0, 4.6,
6.3, 7.6, 13.2, 8.6, 4.9,
9.3, 6.3, 11.8, 15.9, 7.6))
q1_data
treatment_total = q1_data %>%
group_by(Treatment) %>%
summarize(Total_yield = sum(Yield))
treatment_total
total_yield = sum(treatment_total$Total_yield)
cat("The yields in bushels per acre from an experiment is", total_yield)
cor_fct_q1 = total_yield ^2 / nrow(q1_data)
cat("The correction factor is:\n\t\t", cor_fct_q1)
tot_ss_q1 = sum(q1_data$Yield^2) - cor_fct_q1
cat("The total sum of squares is:\n\t\t", tot_ss_q1)
Field_tot_q1 = q1_data %>%
group_by(Fields) %>%
summarize(Field_Yield = sum(Yield))
Field_tot_q1
Rss_q1 = (sum(Field_tot_q1$Field_Yield^2) / nrow(Field_tot_q1)) - cor_fct_q1
cat("The row sum of squares is:\n\t\t", Rss_q1)
Acre_tot_q1 = q1_data %>%
group_by(Acre) %>%
summarize(Acre_Yield = sum(Yield))
Acre_tot_q1
Css_q1 = (sum(Acre_tot_q1$Acre_Yield^2) / nrow(Acre_tot_q1)) - cor_fct_q1
cat("The column sum of squares is:\n\t\t", Css_q1)
Tss_q1 = sum(treatment_total$Total_yield^2)/ nrow(treatment_total) - cor_fct_q1
cat("The treatment sum of squares is:\n\t\t", Tss_q1)
error_ss_q1 = tot_ss_q1 - Rss_q1 - Css_q1 - Tss_q1
cat("The error sum of squares is:\n\t\t", error_ss_q1)
df_row = nrow(Field_tot_q1) - 1
df_col = nrow(Acre_tot_q1) - 1
df_treat = nrow(treatment_total) - 1
df_total = nrow(q1_data) -1
df_err = df_total - df_row - df_col - df_treat
ms_row = Rss_q1 / df_row
ms_col = Css_q1/ df_col
ms_treat = Tss_q1/ df_treat
ms_err = error_ss_q1/df_err
f_treat = ms_treat/ ms_err
cat("The f-statistic is:\n\t\t", f_treat)
p_treat = pf(f_treat, df_treat, df_total, lower.tail = F)
cat("The p-value for treatment is:\n\t\t",p_treat)
p_acre = pf(ms_col/ms_err, df_col, df_total, lower.tail = F)
cat("The p-value for Acre is:\n\t\t",p_acre)
p_field = pf(ms_row/ms_err, df_row, df_total, lower.tail = F)
cat("The p-value for Field is:\n\t\t",p_field)
q1_data$Treatment = as.factor(q1_data$Treatment)
q1_aov = aov(Yield~Fields + Acre + Treatment, data = q1_data)
summary(q1_aov)
lsd_q1 = LSD.test(aov(Yield~Treatment, data = q1_data), "Treatment", p.adj = "none")
lsd_q1$groups
library(ggplot2)
ggplot(q1_data, aes(x = Treatment, y = Yield, fill = Treatment))+
geom_boxplot()+
labs(
title = "Boxplot of Yield for each Treatment",
x = "Treatment",
y = "Spread"
)+
theme_minimal()+
scale_fill_brewer(palette = "Set3")
sd(c(7.96, 6.84, 6.46))
median( q1_data[q1_data$Treatment %in% c("A", "B","D"), "Yield"])
sd(c(6.84, 6.46, 5.12))
median( q1_data[q1_data$Treatment %in% c("A", "B","D"), "Yield"])
q2_data = data.frame(Steer = rep(1:6, each = 6),
Period = rep(1:6, times = 6),
Treatment = c('B', 'D', 'C', 'F', 'A', 'E',
'A', 'F', 'D', 'C', 'E', 'B',
'C', 'A', 'B', 'E', 'F', 'D',
'E', 'B', 'F', 'D', 'C', 'A',
'D', 'C', 'E', 'A', 'B', 'F',
'F', 'E', 'A', 'B', 'D', 'C'),
Digestion = c(61.1, 69.3, 67.6, 61.6, 58.8,65.2,
56.9, 59.1, 64.0, 61.0, 65.7, 56.6,
66.5, 62.2, 61.1, 66.2, 62.0, 62.2,
66.7, 67.4, 63.6, 53.2, 61.7, 62.0,
67.8, 64.7, 63.6, 53.2, 61.7, 62.0,
71.4, 67.5, 55.8, 63.2, 68.0, 62.9))
q2_data
q2_data$Treatment = as.factor(q2_data$Treatment)
str(q2_data)
q2_aov = aov(Digestion~Steer + Period + Treatment, data = q2_data)
summary(q2_aov)
lsd_q2 = LSD.test(aov(Digestion~Treatment, data = q2_data), "Treatment", p.adj = "none")
lsd_q2$groups
ggplot(q2_data, aes(x = Treatment, y = Digestion, fill = Treatment))+
geom_boxplot()+
labs(
title = "Boxplot of Digestion for each Ration",
x = "Ration",
y = "Spread"
)+
theme_minimal()+
scale_fill_brewer(palette = "Set3")
?ts()
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
timeseries_data = read_excel("timeseries_data.xlsx")
timeseries_data = ts(timeseries_data$Sales, start = c(2017, 1), frequency = 12)
head(timeseries_data)
library(readxl)
timeseries_data = read_excel("timeseries_data.xlsx")
timeseries_data = ts(timeseries_data$Sales, start = "2017-01", frequency = 12)
library(readxl)
timeseries_data = read_excel("timeseries_data.xlsx")
head(timeseries_data)
timeseries_data = timeseries_data %>% separate(Date, into = c("Year", "Month"), sep = "-")
knitr::opts_chunk$set(echo = TRUE)
Sys.setenv(RETICULATE_PYTHON = "C:/Users/ADMIN/anaconda/python.exe")
reticulate::repl_python()
import pandas as pd
data = pd.read_csv("timeseries_data.csv")
data.head
# convert to excel
data.to_excel('timeseries_data.xlsx', index = False)
quit
library(readxl)
timeseries_data = read_excel("timeseries_data.xlsx")
head(timeseries_data)
library(tidyr)
library(dplyr)
timeseries_data = timeseries_data %>% separate(Date, into = c("Year", "Month"), sep = "-")
timeseries_data$Year = as.numeric(timeseries_data$Year )
timeseries_data$Month = as.numeric(timeseries_data$Month)
timeseries_data = ts(timeseries_data$Sales, start = c(2017, 1), frequency = 12)
head(timeseries_data)
time(timeseries_data)
timeseries_df = data.frame(Time = time(timeseries_data),
Sales = as.vector(timeseries_data))
head(timeseries_df)
library(ggplot2)
ggplot(df, aes(x = Time, y = Sales)) +
geom_line() +  # Adds a line plot
labs(title = "Sales Over Time", x = "Time", y = "Sales") +
theme_minimal()
library(ggplot2)
ggplot(timeseries_df, aes(x = Time, y = Sales)) +
geom_line() +
labs(title = "Sales Over Time", x = "Time", y = "Sales") +
theme_minimal()
?ggplot()
timeseries_df = data.frame(Time = as.numeric(time(timeseries_data)),
Sales = as.vector(timeseries_data))
head(timeseries_df)
library(ggplot2)
ggplot(timeseries_df, aes(x = Time, y = Sales)) +
geom_line() +
labs(title = "Sales Over Time", x = "Time", y = "Sales") +
theme_minimal()
library(tseries)
k = trunc((nrow(timeseries_df)-1)^(1/3)) # according to r documentation this is the lag value
adf.test(timeseries_data$Sales, k = k)
library(tseries)
k = trunc((nrow(timeseries_df)-1)^(1/3)) # according to r documentation this is the lag value
adf.test(timeseries_df$Sales, k = k)
library(MASS)
bx_cox = boxcox(lm(timeseries_df$Sales~1))
lambda = bx_cox$x[which.max(bx_cox$y)]
lambda
timeseries_df$transformed = ((timeseries_df$Sales ^ lambda) - 1)/ lambda
head(timeseries_df)
plot_data_2 = timeseries_df
ggplot(plot_data_2, aes(x = Time, group = 1)) +
geom_line(aes(y = Sales, color = "original")) +
geom_line(aes(y = transformed, color = "transformed")) +
labs(title = "Time Series and Box-Cox transformed Data of Sales since 2017",
x = "Year",
y = "Sales") +
scale_color_manual(name = "Legend", values = c("original" = "red", "transformed"= "blue"))+
theme_minimal() +
View(timeseries_df)
plot_data_2 = timeseries_df
ggplot(plot_data_2, aes(x = Time, group = 1)) +
geom_line(aes(y = Sales, color = "original")) +
geom_line(aes(y = transformed, color = "transformed")) +
labs(title = "Time Series and Box-Cox transformed Data of Sales since 2017",
x = "Year",
y = "Sales") +
scale_color_manual(name = "Legend", values = c("original" = "red", "transformed"= "blue"))+
theme_minimal()
adf.test(timeseries_data$transformed, k = k)
adf.test(timeseries_df$transformed, k = k)
mean_yt = mean(timeseries_df$Sales)
mean_yt
auto_cor = timeseries_df[, c(1, 3)]
View(auto_cor)
auto_corr_func = function(data, k){
n = length(data)
mu = mean(data)
# T = n
# Y_t - mu = y_{k+ 1}, ..., y_{n} like in class (91, 45, 89,...) are moved 1 step below for eack new k the y column. new data mean variation
# Y_{t -k} - original column but not last value y_1, ..., y_{n-k}. original mean variation
# denominator is just the original column variance
num = sum(((data[(k+1): n]) - mu)  *((data[1: (n-k)]) - mu))
denom = sum((data -mu)^2)
autocorr = num/denom
return(autocorr)
}
for(i in seq(0,20)){
col_name = paste("ACF_k_", i)
auto_cor[[col_name]] = auto_corr_func(auto_cor$transformed, i)
}
auto_cor
library(stats)
plot_data_3 = data.frame(Lag = seq(0,20),
ACF = unlist(auto_cor[, 4:ncol(auto_cor)][1,], use.names = FALSE))
library(stats)
plot_data_3 = data.frame(Lag = seq(0,20),
ACF = unlist(auto_cor[, 3:ncol(auto_cor)][1,], use.names = FALSE))
ggplot(plot_data_3, aes(x = Lag, y = ACF)) +
geom_bar(stat = "identity", fill = "steelblue") +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(
title = "Autocorrelation Function (ACF)",
x = "Lag",
y = "Autocorrelation") +
theme_minimal()
var(plot_data_3$ACF)
sd(plot_data_3$ACF)
library(stats)
plot_data_3 = data.frame(Lag = seq(0,20),
ACF = unlist(auto_cor[, 3:ncol(auto_cor)][1,], use.names = FALSE))
ggplot(plot_data_3, aes(x = Lag, y = ACF)) +
geom_bar(stat = "identity", fill = "steelblue") +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
geom_hline(yintercept = sd(plot_data_3$ACF), linetype = "dashed", color = "red") +
labs(
title = "Autocorrelation Function (ACF)",
x = "Lag",
y = "Autocorrelation") +
theme_minimal()
?ts()
head(auto_cor)
tail(auto_cor)
read.csv()
read.csv(timeseries_data.csv)
data = read.csv("timeseries_data.csv")
head(data)
setwd("C:/Users/ADMIN/Documents/SEM 2 2024/STA3050 time series/Tasks_and_Assignments/task 3")
gc()
knitr::opts_chunk$set(echo = TRUE)
data = read.csv("timeseries_data.csv")
head(data)
# convert to excel
writexl::write_xlsx(data, "timeseries_data.xlsx")
library(readxl)
timeseries_data = read_excel("timeseries_data.xlsx")
head(timeseries_data)
library(tidyr)
library(dplyr)
timeseries_data = timeseries_data %>% separate(Date, into = c("Year", "Month"), sep = "-")
timeseries_data$Year = as.numeric(timeseries_data$Year )
timeseries_data$Month = as.numeric(timeseries_data$Month)
timeseries_data = ts(timeseries_data$Sales, start = c(2017, 1), frequency = 12)
head(timeseries_data)
timeseries_df = data.frame(Time = as.numeric(time(timeseries_data)),
Sales = as.vector(timeseries_data))
head(timeseries_df)
library(ggplot2)
ggplot(timeseries_df, aes(x = Time, y = Sales)) +
geom_line() +
labs(title = "Sales Over Time", x = "Time", y = "Sales") +
theme_minimal()
library(tseries)
k = trunc((nrow(timeseries_df)-1)^(1/3)) # according to r documentation this is the lag value
adf.test(timeseries_df$Sales, k = k)
library(MASS)
bx_cox = boxcox(lm(timeseries_df$Sales~1))
lambda = bx_cox$x[which.max(bx_cox$y)]
lambda
timeseries_df$transformed = ((timeseries_df$Sales ^ lambda) - 1)/ lambda
head(timeseries_df)
plot_data_2 = timeseries_df
ggplot(plot_data_2, aes(x = Time, group = 1)) +
geom_line(aes(y = Sales, color = "original")) +
geom_line(aes(y = transformed, color = "transformed")) +
labs(title = "Time Series and Box-Cox transformed Data of Sales since 2017",
x = "Year",
y = "Sales") +
scale_color_manual(name = "Legend", values = c("original" = "red", "transformed"= "blue"))+
theme_minimal()
adf.test(timeseries_df$transformed, k = k)
mean_yt = mean(timeseries_df$Sales)
mean_yt
auto_cor = timeseries_df[, c(1, 3)]
auto_corr_func = function(data, k){
n = length(data)
mu = mean(data)
# T = n
# Y_t - mu = y_{k+ 1}, ..., y_{n} like in class (91, 45, 89,...) are moved 1 step below for eack new k the y column. new data mean variation
# Y_{t -k} - original column but not last value y_1, ..., y_{n-k}. original mean variation
# denominator is just the original column variance
num = sum(((data[(k+1): n]) - mu)  *((data[1: (n-k)]) - mu))
denom = sum((data -mu)^2)
autocorr = num/denom
return(autocorr)
}
for(i in seq(0,20)){
col_name = paste("ACF_k_", i)
auto_cor[[col_name]] = auto_corr_func(auto_cor$transformed, i)
}
head(auto_cor)
tail(auto_cor)
library(stats)
plot_data_3 = data.frame(Lag = seq(0,20),
ACF = unlist(auto_cor[, 3:ncol(auto_cor)][1,], use.names = FALSE))
ggplot(plot_data_3, aes(x = Lag, y = ACF)) +
geom_bar(stat = "identity", fill = "steelblue") +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
geom_hline(yintercept = sd(plot_data_3$ACF), linetype = "dashed", color = "red") +
labs(
title = "Autocorrelation Function (ACF)",
x = "Lag",
y = "Autocorrelation") +
theme_minimal()
